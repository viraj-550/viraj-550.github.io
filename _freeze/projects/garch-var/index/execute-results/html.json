{
  "hash": "c5f96242159bc719f6de27622bb3ffbb",
  "result": {
    "markdown": "---\ntitle: \"Balancing Risk and Reward: Copula-GARCH Framework for Portfolio Optimiziation\"\nsubtitle: \"A Comprehensive Study of SPXL ETF and BAC Stock for VaR Insights\"\nauthor: \"Viraj Chordiya\"\ndate: '2022-11-30'\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    code-line-numbers: true\n    toc: True\nexecute:\n  cache: true\n  warning: false\ncategories: [Financial Econometrics, Portfolio Optimization, Copula, R]\nbibliography: [\"reference.bib\"]\nnocite: |\n  @*\n---\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_7f9daa0631fbca3732e40c758250ecdb'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_9df224eb0a723eaf4212c38051eb794e'}\n<style type=\"text/css\">\n.justify {\n  text-align: justify !important\n}\n</style>\n:::\n\n\n::: justify\n# Introduction\n\nIn today's volatile financial landscape, effective portfolio management has become an indispensable tool for mitigating investment risks that simply cannot be overlooked. The role of a portfolio manager is paramount, as they navigate this complex terrain with the overarching objective of minimizing risks while maximizing returns for their clients.\n\nThe goal of this project is to conduct a comprehensive analysis of two distinct financial instruments: the Direxion Daily S&P 500 Bull 3X Shares (SPXL) Exchange-Traded Fund (ETF) and Bank of America Corp (NYSE: BAC) stock. Our primary goal is to craft an optimal portfolio of these two assets that not only forecasts Value-at-Risk (VaR) but also actively reduces it.\n\nThe Direxion Daily S&P 500 Bull 3X Shares ETF, a 300% leveraged vehicle based on the performance of the S&P 500 index, offers 3x amplified returns as compared to the benchmark return on a daily basis. In contrast, Bank of America Corp (BAC), a steadfast and established financial institution, has a history of providing stable returns. The fusion of these two financial assets into an optimal portfolio promises a potential of handsome returns while managing VaR. We collect historical ten year daily OHLC data for both the instruments from Yahoo Finance using `quantmod::getSymbols()` in R.\n\nSubsequently, we perform the following analysis to construct an optimal portfolio:\n\n-   **Exploring the Data**: We conduct a rigorous examination of the data to unveil any time-dependent patterns and potential volatility clustering, that provide insights into the behavior of these financial instruments.\n-   **Time Series Modeling**: Employing a $AR(1) + GARCH(1,1)$ model, we seek to model the logarithmic returns of each product, providing us a deeper understanding of their inherent dynamics.\n-   **Copula Analysis**: We fit t-distributions to the standardized errors of both models. To study the dependence structure of both the residues, we explore various copulas such as the t-Copula, Gaussian Copula, Gumbel Copula, Clayton Copula, and Frank Copula. The selection of the most suitable copula is based on minimizing the Akaike Information Criterion (AIC).\n-   **Residual Analysis**: Rigorous evaluation of the standardized residues of our model is carried out, aiming to detect any potential serial correlation. This step involves the utilization of autocorrelation plots and weighted versions of the Ljung-Box test, ultimately confirming the appropriateness of the $AR(1) + GARCH(1,1)$ model for our dataset.\n-   **VaR Forecasting**: Employing advanced numerical methods, we forecast Value-at-Risk for various portfolios comprising of SPXL and BAC. Our findings reveal that VaR is responsive to varying proportions of SPXL within the portfolio. Notably, we uncover that VaR tends to rise as the allocation to SPXL increases.\n\nIn essence, our project serves as a comprehensive exploration of the dynamic interplay between these financial assets, offering valuable insights and strategies for optimizing portfolio performance while diligently managing risks in an ever-evolving financial landscape.\n\n:::\n\n::: {.cell warnings='false' hash='index_cache/html/unnamed-chunk-3_14a0498fec8605376002717cc0233b2b'}\n\n```{.r .cell-code}\n# Importing Packages\n\nlibrary(quantmod)\nlibrary(xts)\nlibrary(gridExtra)\nlibrary(MASS)\nlibrary(fGarch)\nlibrary(sn)\nlibrary(copula)\nlibrary(ks)\nlibrary(stargazer)\nlibrary(patchwork)\nlibrary(rugarch)\nlibrary(psych)\nlibrary(ggplot2)\nlibrary(tseries)\nlibrary(modelsummary)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n# Data\n::: justify\nWe collect ten years daily OHLC data of Direxion Daily S&P 500 Bull 3X Shares (SPXL) and Bank of America Corp (NYSE: BAC). SPXL is a three times leveraged ETF mirroring the S&P 500 index. Hence, it provides a 300% of the S&P 500 index's daily return. The data is collected from Yahoo finance for period 2012/11 - 2022/11 using the `getSymbol()` function from the `quantmod` library. The table represents the summary statistics of daily adjusted closing stock price, and log returns of both the instruments.\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_7b0576d5d1bbecb367bfa559f8dad29f'}\n\n```{.r .cell-code}\n# Assigning Date\n\nstart <- as.Date(\"2012-11-09\")\nend <- as.Date(\"2022-11-10\")\n\nspxl_df <- getSymbols(\"SPXL\", from = start, to = end, src = \"yahoo\",\n                       auto.assign = F)\nbac_df <- getSymbols(\"BAC\", from = start, to = end, src = \"yahoo\",\n                       auto.assign = F)\n\n\ndaily_df <- cbind(spxl_df$SPXL.Adjusted, bac_df$BAC.Adjusted)\n\ncolnames(daily_df) <- c(\"SPXL\", \"BAC\")\n\ndaily_df$SPXL_r <- diff(log(daily_df$SPXL))\ndaily_df$BAC_r <- diff(log(daily_df$BAC))\n\ndaily_df <- na.omit(daily_df)\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_d4b8e782ade91b70402506381a0e30c5'}\n\n```{.r .cell-code}\nsummary_df <- describe(daily_df, ranges = F)\ncolnames(summary_df) <- c(\"Variable\", \"N\", \"Mean\", \"Std\", \"Skew\", \"Kurtosis\", \"S.E.\")\nsummary_df$Variable <- c(\"SPXL\", \"BAC\", \"SPXL Returns\", \"BAC Returns\")\ndatasummary_df(summary_df,\n               title = \"Table 1. Summary Statistics\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Table 1. Summary Statistics</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Â Variable </th>\n   <th style=\"text-align:left;\"> N </th>\n   <th style=\"text-align:left;\"> Mean </th>\n   <th style=\"text-align:left;\"> Std </th>\n   <th style=\"text-align:left;\"> Skew </th>\n   <th style=\"text-align:left;\"> Kurtosis </th>\n   <th style=\"text-align:left;\"> S.E. </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> SPXL </td>\n   <td style=\"text-align:left;\"> 2517.00 </td>\n   <td style=\"text-align:left;\"> 42.77 </td>\n   <td style=\"text-align:left;\"> 31.46 </td>\n   <td style=\"text-align:left;\"> 1.24 </td>\n   <td style=\"text-align:left;\"> 0.85 </td>\n   <td style=\"text-align:left;\"> 0.63 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BAC </td>\n   <td style=\"text-align:left;\"> 2517.00 </td>\n   <td style=\"text-align:left;\"> 22.13 </td>\n   <td style=\"text-align:left;\"> 9.52 </td>\n   <td style=\"text-align:left;\"> 0.59 </td>\n   <td style=\"text-align:left;\"> -0.56 </td>\n   <td style=\"text-align:left;\"> 0.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SPXL Returns </td>\n   <td style=\"text-align:left;\"> 2517.00 </td>\n   <td style=\"text-align:left;\"> 0.00 </td>\n   <td style=\"text-align:left;\"> 0.03 </td>\n   <td style=\"text-align:left;\"> -1.52 </td>\n   <td style=\"text-align:left;\"> 20.38 </td>\n   <td style=\"text-align:left;\"> 0.00 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BAC Returns </td>\n   <td style=\"text-align:left;\"> 2517.00 </td>\n   <td style=\"text-align:left;\"> 0.00 </td>\n   <td style=\"text-align:left;\"> 0.02 </td>\n   <td style=\"text-align:left;\"> -0.07 </td>\n   <td style=\"text-align:left;\"> 9.85 </td>\n   <td style=\"text-align:left;\"> 0.00 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: justify\nThere are a total of 2517 observations in total. Prices and log returns of both the financial instruments are asymmetric. SPXL daily prices are extremely skewed to the right, while SPXL returns are extremely skewed to the left. Moreover, BAC daily prices are slightly skewed to the right while the returns are slightly skewed to the left. The excess kurtosis for the log returns of both assets show that returns are not normally distributed.\n:::\n## Time series graphs and distribution plots\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_4061a1e3e0c42834c4ff5df766adc8be'}\n\n```{.r .cell-code}\nplot1 <- ggplot(spxl_df, aes(x = Index, y = SPXL.Adjusted))+\n  geom_line(color = \"steelblue\") + \n  ggtitle(\"SPXL Daily Price\") +   \n  xlab(\"Date\") + \n  ylab(\"Price($)\") + \n  theme(plot.title = element_text(hjust = 0.5)) + \n  scale_x_date(date_labels = \"%y-%m\", date_breaks = \"1 year\") +\n  theme_bw()\n\nplot2 <- ggplot(bac_df, aes(x = Index, y = BAC.Adjusted))+\n  geom_line(color = \"darkorange2\") + \n  ggtitle(\"BAC Daily Price\") +   \n  xlab(\"Date\") + \n  ylab(\"Price($)\") + \n  theme(plot.title = element_text(hjust = 0.5)) + \n  scale_x_date(date_labels = \"%y-%m\", date_breaks = \"1 year\") + \n  theme_bw()\n\nplot1 / plot2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Exploratory Data Analysis\n::: justify\nFirstly, we check for weak stationarity by investigating the time series plots of log returns of both the financial instruments. Next, we conduct the Augmented Dickey Fuller (ADF) test to check for the presence of unit root.\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_975cd0cc916495be92ecebe969af1ea6'}\n\n```{.r .cell-code}\n# Plotting log returns\n\nplot_spxl_r <- ggplot(daily_df, aes(x = Index, y = SPXL_r))+\n  geom_line(color = \"steelblue\") + \n  ggtitle(\"SPXL Log Returns\") +   \n  xlab(\"Date\") + \n  ylab(\"Log Returns\") + \n  theme(plot.title = element_text(hjust = 0.5)) + \n  scale_x_date(date_labels = \"%y-%m\", date_breaks = \"1 year\") + \n  theme_bw()\n\nplot_bac_r <- ggplot(daily_df, aes(x = Index, y = BAC_r))+\n  geom_line(color = \"darkorange2\") + \n  ggtitle(\"BAC Log Returns\") +   \n  xlab(\"Date\") + \n  ylab(\"Log Returns\") + \n  theme(plot.title = element_text(hjust = 0.5)) + \n  scale_x_date(date_labels = \"%y-%m\", date_breaks = \"1 year\") + \n  theme_bw()\n\nplot_spxl_r / plot_bac_r\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_261cbe0788d2e78929062e1f35fc4c20'}\n\n```{.r .cell-code}\nadf.test(daily_df$SPXL_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  daily_df$SPXL_r\nDickey-Fuller = -13.314, Lag order = 13, p-value = 0.01\nalternative hypothesis: stationary\n```\n:::\n\n```{.r .cell-code}\nadf.test(daily_df$BAC_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tAugmented Dickey-Fuller Test\n\ndata:  daily_df$BAC_r\nDickey-Fuller = -12.962, Lag order = 13, p-value = 0.01\nalternative hypothesis: stationary\n```\n:::\n:::\n\n::: justify\nUpon visual inspection, it looks like both the log returns are stationary. Moreover, from the ADF test, we fail to reject the null hypothesis of non-stationarity at 1% confidence.\n\nIn order to look for time dependency and volatility clustering of log returns of SPLX and BAC, From the graphs, it is evident that both series display time varying volatility. Moreover, volatility clusters together. For better analysis, we need to model the nonconstant volatility.\n:::\n\n::: {.cell hash='index_cache/html/ggplot_f42e486540279a1383db9c796d37cf2b'}\n\n```{.r .cell-code}\n# ACF plots\nggacf <- function(x, ci=0.95, type=\"correlation\", xlab=\"Lag\", ylab=NULL,\n                  ylim=NULL, main=NULL, ci.col=\"blue\", lag.max=NULL) {\n\n    x <- as.data.frame(x)\n\n    x.acf <- acf(x, plot=F, lag.max=lag.max, type=type)\n\n    ci.line <- qnorm((1 - ci) / 2) / sqrt(x.acf$n.used)\n\n    d.acf <- data.frame(lag=x.acf$lag, acf=x.acf$acf)\n\n    g <- ggplot(d.acf, aes(x=lag, y=acf)) +\n        geom_hline(yintercept=0) +\n        geom_segment(aes(xend=lag, yend=0)) +\n        geom_hline(yintercept=ci.line, color=ci.col, linetype=\"dashed\") +\n        geom_hline(yintercept=-ci.line, color=ci.col, linetype=\"dashed\") +\n        theme_bw() +\n        xlab(\"Lag\") +\n        ggtitle(ifelse(is.null(main), \"\", main)) +\n        if (is.null(ylab))\n            ylab(ifelse(type==\"partial\", \"PACF\", \"ACF\"))\n        else\n            ylab(ylab)\n\n    g\n}\n\nspxl_acf <- ggacf(daily_df$SPXL_r, main = \"SPXL\")\nspxl_acf2 <- ggacf(daily_df$SPXL_r ** 2, main = \"SPXL Squared\")\nbac_acf <- ggacf(daily_df$BAC_r, main = \"BAC\")\nbac_acf2 <- ggacf(daily_df$BAC_r ** 2, main = \"BAC Squared\")\n\n(spxl_acf + spxl_acf2) / (bac_acf + bac_acf2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/ggplot-1.png){width=672}\n:::\n:::\n\n::: justify\nFrom the log return graphs, it is evident that both series display time varying volatility. Moreover, ACF plots of squared series of both stocks show significant serial correlation. For better analysis, we need to model time dependence and non-constant volatility.\n:::\n------------------------------------------------------------------------\n\n# Time Series Model\n\n## AR(1)-GARCH(1,1) Model\n::: justify\nIn order to model autocorelation and volatility clustering, we combine an AR(1) model that has a nonconstant conditional mean but a constant conditional variance with a GARCH(1,1) model that has conditional mean and the variance of data depends on the past. Additionally, in a GARCH model, conditional standard deviation exhibits more persistent periods of low and high volatility.\n\nThe $AR(1) - GARCH(1,1)$ is model is as follows:\n\n$$ X_t = \\mu + \\phi X_{t-1} + e_t, \\quad e_t =  \\sigma_{t}\\varepsilon_{t}, \\quad \\sigma^2_t = \\omega + \\alpha e^2_{t-1} + \\beta \\sigma^2_{t-1} $$ $$ \\tilde X_t = \\tilde \\mu + \\tilde \\phi \\tilde X_{t-1} + \\tilde e_t, \\quad \\tilde e_t =  \\tilde \\sigma_{t}\\tilde \\varepsilon_{t}, \\quad \\tilde \\sigma^2_t = \\tilde \\omega + \\tilde \\alpha \\tilde e^2_{t-1} + \\tilde \\beta \\tilde \\sigma^2_{t-1} $$\n\nwhere, $X_t$ is the daily log returns of SPXL and $\\tilde X_t$ is the daily log returns of BAC.\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-9_0d156f5b2d1245cbe65302f55b20aa03'}\n\n```{.r .cell-code}\nspxl <- as.vector(daily_df$SPXL_r)\nbac <- as.vector(daily_df$BAC_r)\n\n# Fitting an AR(1) + GARCH(1,1) Model\nspxl_spec <- ugarchspec(mean.model=list(armaOrder=c(1,0)),\n                        variance.model=list(garchOrder=c(1,1)))\nspxl_fit <- ugarchfit(spxl_spec, data = spxl)\n\nbac_spec <- ugarchspec(mean.model=list(armaOrder=c(1,0)),\n                        variance.model=list(garchOrder=c(1,1)))\nbac_fit <- ugarchfit(bac_spec, data = bac)\n```\n:::\n\n\n## Residual Copula Modelling\n::: justify\nIn order to work with a portfolio of Direxion Daily S&P 500 Bull 3X Shares (SPXL) and Bank of America Corp (BAC), we need to model both the series as a copula to extract the dependence structure between the two financial instruments. In the project, we particulary study the dependent structure of the standardized residuals of an $AR(1) - GARCH(1,1)$ model fitted to both the series.\n\nFirst, we fit a Student t distribution to both $\\varepsilon_t$ and $\\tilde \\varepsilon_t$ using the `fitdistr()` function from the `MASS` library.\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-10_f8b52886c9f8bb76b809ee7cc8d96253'}\n\n```{.r .cell-code}\n# Standardized Residuals\n\nspxl_res <- as.vector(residuals(spxl_fit, standardize = T))\nbac_res <- as.vector(residuals(bac_fit, standardize = T))\n\n# Fitting t-distribution\nspxl_res_t <- fitdistr(spxl_res, \"t\")\nbac_res_t <- fitdistr(bac_res, \"t\")\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-11_df46f682ba29de961f42e49ffbd6094e'}\n\n```{.r .cell-code}\n# Fitting t-density plots\npar(mfrow = c(1,2))\nn <- length(spxl_res)\n\nx1 <- qt((1:n)/(n+1), df = 5)\nx2 <- qt((1:n)/(n+1), df = 5)\n\nqqplot(sort(spxl_res), x1, xlab=\"Standardized Residuals\",\n       ylab=\"t-quantiles\",\n       main = \"SPXL Residual t-plot, DF = 5\")\n\nqqplot(sort(bac_res), x2, xlab=\"Standardized Residuals\",\n       ylab=\"t-quantiles\",\n       main = \"BAC Residual t-plot, DF = 5\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: justify\nA t-distribution with df = 5 fits well to the SPXL and BAC residuals. The qqplot for both the instruments is a straight line except for a few outliers. Given that the total number of observations (n = 2517) is high enough, the outliers are a small fraction of the sample.\n\nSecond, we transform the residuals into marginal t - distributions and fit t-copula, Gaussian copula, Gumbel Copula, Clayton and Frank copulas. We select the best fit copula by minimizing AIC. We select t-copula as it minimizes AIC.\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-12_ea3fe627f31948898f6b410543554cdc'}\n\n```{.r .cell-code}\n# Transform residues into uniform distribution\n\nspxl_uniform <- pt(spxl_res, df = spxl_res_t$estimate[3])\nbac_uniform <- pt(bac_res, df = bac_res_t$estimate[3])\n\nU_hat <- cbind(spxl_uniform, bac_uniform)\ncolnames(U_hat) <- c(\"SPXL_U\", \"BAC_U\")\n\ntau <- as.numeric(cor.test(spxl_uniform, bac_uniform, \n                           method=\"kendall\")$estimate)\nomega <- sin(tau * pi/2)\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_c76f7d7d52598f1ed8f3cf7d9d74cb3a'}\n\n```{.r .cell-code}\n# Fit t-Copula\nCt <- fitCopula(copula = tCopula(dim = 2), data = U_hat,\n                method = \"ml\", start = c(omega, 10))\n\n# Log-Likelihood\nlog_lik_t <- loglikCopula(param = Ct@estimate, u = U_hat, \n                          copula = tCopula(dim = 2))\naic_t <- (2 * length(Ct@estimate)) - (2 * abs(log_lik_t))\naic_t\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1516.131\n```\n:::\n\n```{.r .cell-code}\n# Gaussian Copula\nCgauss <- fitCopula(copula = normalCopula(dim = 2), data = U_hat, \n                    method = \"ml\", start=c(omega))\nlog_lik_gauss <- loglikCopula(param = Cgauss@estimate, u = U_hat, \n                          copula = normalCopula(dim = 2))\n\naic_gauss <- (2 * length(Cgauss@estimate)) - (2 *abs(log_lik_gauss))\naic_gauss\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1411.64\n```\n:::\n\n```{.r .cell-code}\n# Gumbel Copula\nC_gumbel <- fitCopula(copula = gumbelCopula(dim = 2), data =U_hat,\n                      method = \"ml\")\nlog_lik_gumbel <- loglikCopula(param = C_gumbel@estimate, u = U_hat,\n                               copula = gumbelCopula(dim = 2))\naic_gumbel <- (2 * length(C_gumbel@estimate)) -(2*abs(log_lik_gumbel))\naic_gumbel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1388.308\n```\n:::\n\n```{.r .cell-code}\n# Clayton Copula\n\nC_clayton <- fitCopula(copula = claytonCopula(dim = 2), data = U_hat,\n                      method = \"ml\")\nlog_lik_clayton <- loglikCopula(param = C_clayton@estimate, u = U_hat,\n                                copula = claytonCopula(dim = 2))\naic_clayton <- (2 * length(C_clayton@estimate)) -(2*abs(log_lik_clayton))\naic_clayton\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1213.358\n```\n:::\n\n```{.r .cell-code}\n# Frank Copula\n\nCfrank <- fitCopula(copula = frankCopula(1, dim = 2), data = U_hat,\n                    method = \"ml\")\n\nlog_lik_frank <- loglikCopula(param = Cfrank@estimate, u = U_hat,\n                              copula = frankCopula(dim = 2))\naic_frank <- (2 * length(Cfrank@estimate)) - (2 *abs(log_lik_frank))\naic_frank\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1395.342\n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Residual Analysis\n::: justify\nWe conduct a residual analysis on the standardized residuals $\\varepsilon_t$ and $\\tilde \\varepsilon$ to check the fit of the $AR(1) + GARCH(1,1)$ model.\n\nFirst, we inspect the standardized residuals and squared standardized residuals for autocorrelation. The figure below plots the `acf()` function for the four series.\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_cd3b887009af14180973be0fdb0e2168'}\n\n```{.r .cell-code}\nspxl_res_acf <- ggacf(spxl_res, main = \"SPXL Std. Residuals\")\nspxl_res_acf2 <- ggacf(spxl_res ** 2, main = \"Squared SPXL Std. Residuals\")\nbac_res_acf <- ggacf(bac_res, main = \"BAC Std. Residuals\")\nbac_res_acf2 <- ggacf(bac_res ** 2, main = \"Squared BAC Std. Residuals\")\n\n(spxl_res_acf + spxl_res_acf2) / (bac_res_acf + bac_res_acf2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: justify\nThe AR(1) + GARCH(1,1) model fits very well to SPXL and BAC. The standardized residuals and the squared standardized residuals of both the models show no significant serial correlation at 95% confidence.\n\nNext we look at the following box tests to check autocorrelation\n:::\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_dff0dae2dc763b95b42e36587bdb0bbc'}\n\n```{.r .cell-code}\nshow(spxl_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n*---------------------------------*\n*          GARCH Model Fit        *\n*---------------------------------*\n\nConditional Variance Dynamics \t\n-----------------------------------\nGARCH Model\t: sGARCH(1,1)\nMean Model\t: ARFIMA(1,0,0)\nDistribution\t: norm \n\nOptimal Parameters\n------------------------------------\n        Estimate  Std. Error  t value Pr(>|t|)\nmu      0.002425    0.000386   6.2774 0.000000\nar1    -0.057599    0.022519  -2.5578 0.010532\nomega   0.000039    0.000005   7.2772 0.000000\nalpha1  0.234792    0.023529   9.9789 0.000000\nbeta1   0.735780    0.021291  34.5576 0.000000\n\nRobust Standard Errors:\n        Estimate  Std. Error  t value Pr(>|t|)\nmu      0.002425    0.000393   6.1644 0.000000\nar1    -0.057599    0.020538  -2.8045 0.005039\nomega   0.000039    0.000008   4.7666 0.000002\nalpha1  0.234792    0.035225   6.6656 0.000000\nbeta1   0.735780    0.030380  24.2194 0.000000\n\nLogLikelihood : 5725.413 \n\nInformation Criteria\n------------------------------------\n                    \nAkaike       -4.5454\nBayes        -4.5338\nShibata      -4.5454\nHannan-Quinn -4.5412\n\nWeighted Ljung-Box Test on Standardized Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                      2.051  0.1521\nLag[2*(p+q)+(p+q)-1][2]     2.125  0.1742\nLag[4*(p+q)+(p+q)-1][5]     2.965  0.4401\nd.o.f=1\nH0 : No serial correlation\n\nWeighted Ljung-Box Test on Standardized Squared Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                   0.004507  0.9465\nLag[2*(p+q)+(p+q)-1][5]  0.755387  0.9121\nLag[4*(p+q)+(p+q)-1][9]  2.391474  0.8535\nd.o.f=2\n\nWeighted ARCH LM Tests\n------------------------------------\n            Statistic Shape Scale P-Value\nARCH Lag[3] 0.0007028 0.500 2.000  0.9789\nARCH Lag[5] 1.8924935 1.440 1.667  0.4955\nARCH Lag[7] 2.9168770 2.315 1.543  0.5294\n\nNyblom stability test\n------------------------------------\nJoint Statistic:  1.4917\nIndividual Statistics:              \nmu     0.06813\nar1    0.03829\nomega  0.25524\nalpha1 0.74886\nbeta1  0.80326\n\nAsymptotic Critical Values (10% 5% 1%)\nJoint Statistic:     \t 1.28 1.47 1.88\nIndividual Statistic:\t 0.35 0.47 0.75\n\nSign Bias Test\n------------------------------------\n                     t-value      prob sig\nSign Bias           3.751262 0.0001799 ***\nNegative Sign Bias  0.946854 0.3438041    \nPositive Sign Bias  0.004948 0.9960528    \nJoint Effect       20.723476 0.0001202 ***\n\n\nAdjusted Pearson Goodness-of-Fit Test:\n------------------------------------\n  group statistic p-value(g-1)\n1    20     132.0    6.129e-19\n2    30     157.1    1.510e-19\n3    40     178.8    8.634e-20\n4    50     187.7    4.062e-18\n\n\nElapsed time : 0.519062 \n```\n:::\n\n```{.r .cell-code}\nshow(bac_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n*---------------------------------*\n*          GARCH Model Fit        *\n*---------------------------------*\n\nConditional Variance Dynamics \t\n-----------------------------------\nGARCH Model\t: sGARCH(1,1)\nMean Model\t: ARFIMA(1,0,0)\nDistribution\t: norm \n\nOptimal Parameters\n------------------------------------\n        Estimate  Std. Error  t value Pr(>|t|)\nmu      0.001034    0.000323   3.2023 0.001363\nar1     0.032518    0.021631   1.5033 0.132758\nomega   0.000018    0.000004   4.2020 0.000026\nalpha1  0.105468    0.015991   6.5953 0.000000\nbeta1   0.837325    0.026363  31.7610 0.000000\n\nRobust Standard Errors:\n        Estimate  Std. Error  t value Pr(>|t|)\nmu      0.001034    0.000313   3.3035 0.000955\nar1     0.032518    0.020844   1.5601 0.118735\nomega   0.000018    0.000007   2.5283 0.011463\nalpha1  0.105468    0.033066   3.1896 0.001425\nbeta1   0.837325    0.048064  17.4211 0.000000\n\nLogLikelihood : 6693.436 \n\nInformation Criteria\n------------------------------------\n                    \nAkaike       -5.3146\nBayes        -5.3030\nShibata      -5.3146\nHannan-Quinn -5.3104\n\nWeighted Ljung-Box Test on Standardized Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                    0.02465  0.8753\nLag[2*(p+q)+(p+q)-1][2]   0.56006  0.9483\nLag[4*(p+q)+(p+q)-1][5]   1.75866  0.7794\nd.o.f=1\nH0 : No serial correlation\n\nWeighted Ljung-Box Test on Standardized Squared Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                      1.550  0.2131\nLag[2*(p+q)+(p+q)-1][5]     2.058  0.6047\nLag[4*(p+q)+(p+q)-1][9]     3.474  0.6789\nd.o.f=2\n\nWeighted ARCH LM Tests\n------------------------------------\n            Statistic Shape Scale P-Value\nARCH Lag[3]    0.0687 0.500 2.000  0.7932\nARCH Lag[5]    1.2776 1.440 1.667  0.6527\nARCH Lag[7]    2.2188 2.315 1.543  0.6710\n\nNyblom stability test\n------------------------------------\nJoint Statistic:  0.8988\nIndividual Statistics:              \nmu     0.02392\nar1    0.02143\nomega  0.24815\nalpha1 0.57062\nbeta1  0.34991\n\nAsymptotic Critical Values (10% 5% 1%)\nJoint Statistic:     \t 1.28 1.47 1.88\nIndividual Statistic:\t 0.35 0.47 0.75\n\nSign Bias Test\n------------------------------------\n                   t-value      prob sig\nSign Bias           0.3415 0.7327322    \nNegative Sign Bias  3.0886 0.0020331 ***\nPositive Sign Bias  0.5373 0.5910826    \nJoint Effect       17.9996 0.0004399 ***\n\n\nAdjusted Pearson Goodness-of-Fit Test:\n------------------------------------\n  group statistic p-value(g-1)\n1    20     77.00    6.080e-09\n2    30     90.07    3.554e-08\n3    40    105.92    4.275e-08\n4    50    114.09    4.159e-07\n\n\nElapsed time : 0.2202091 \n```\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_18d26e29d9a5b61eaf10d9ff4c16fe87'}\n\n```{.r .cell-code}\nbac_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n*---------------------------------*\n*          GARCH Model Fit        *\n*---------------------------------*\n\nConditional Variance Dynamics \t\n-----------------------------------\nGARCH Model\t: sGARCH(1,1)\nMean Model\t: ARFIMA(1,0,0)\nDistribution\t: norm \n\nOptimal Parameters\n------------------------------------\n        Estimate  Std. Error  t value Pr(>|t|)\nmu      0.001034    0.000323   3.2023 0.001363\nar1     0.032518    0.021631   1.5033 0.132758\nomega   0.000018    0.000004   4.2020 0.000026\nalpha1  0.105468    0.015991   6.5953 0.000000\nbeta1   0.837325    0.026363  31.7610 0.000000\n\nRobust Standard Errors:\n        Estimate  Std. Error  t value Pr(>|t|)\nmu      0.001034    0.000313   3.3035 0.000955\nar1     0.032518    0.020844   1.5601 0.118735\nomega   0.000018    0.000007   2.5283 0.011463\nalpha1  0.105468    0.033066   3.1896 0.001425\nbeta1   0.837325    0.048064  17.4211 0.000000\n\nLogLikelihood : 6693.436 \n\nInformation Criteria\n------------------------------------\n                    \nAkaike       -5.3146\nBayes        -5.3030\nShibata      -5.3146\nHannan-Quinn -5.3104\n\nWeighted Ljung-Box Test on Standardized Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                    0.02465  0.8753\nLag[2*(p+q)+(p+q)-1][2]   0.56006  0.9483\nLag[4*(p+q)+(p+q)-1][5]   1.75866  0.7794\nd.o.f=1\nH0 : No serial correlation\n\nWeighted Ljung-Box Test on Standardized Squared Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                      1.550  0.2131\nLag[2*(p+q)+(p+q)-1][5]     2.058  0.6047\nLag[4*(p+q)+(p+q)-1][9]     3.474  0.6789\nd.o.f=2\n\nWeighted ARCH LM Tests\n------------------------------------\n            Statistic Shape Scale P-Value\nARCH Lag[3]    0.0687 0.500 2.000  0.7932\nARCH Lag[5]    1.2776 1.440 1.667  0.6527\nARCH Lag[7]    2.2188 2.315 1.543  0.6710\n\nNyblom stability test\n------------------------------------\nJoint Statistic:  0.8988\nIndividual Statistics:              \nmu     0.02392\nar1    0.02143\nomega  0.24815\nalpha1 0.57062\nbeta1  0.34991\n\nAsymptotic Critical Values (10% 5% 1%)\nJoint Statistic:     \t 1.28 1.47 1.88\nIndividual Statistic:\t 0.35 0.47 0.75\n\nSign Bias Test\n------------------------------------\n                   t-value      prob sig\nSign Bias           0.3415 0.7327322    \nNegative Sign Bias  3.0886 0.0020331 ***\nPositive Sign Bias  0.5373 0.5910826    \nJoint Effect       17.9996 0.0004399 ***\n\n\nAdjusted Pearson Goodness-of-Fit Test:\n------------------------------------\n  group statistic p-value(g-1)\n1    20     77.00    6.080e-09\n2    30     90.07    3.554e-08\n3    40    105.92    4.275e-08\n4    50    114.09    4.159e-07\n\n\nElapsed time : 0.2202091 \n```\n:::\n:::\n\n::: justify\nThe weighted versions of the Ljung-Box test and their p-values all indicate that the estimated $AR(1) + GARCH(1,1)$ model for the conditional mean and variance is adequate for removing serial correlation from the series and squared series.\n:::\n------------------------------------------------------------------------\n\n# Applications to Portfolio Risk Management\n::: justify\nIn this section, we apply the $AR(1) + GARCH(1,1)$ along with t-Copula residuals to forecast one-step ahead Value-at-Risk at 99% level on the following portfolio consisting of SPXL and BAC with weight $\\rho$:\n\n$$\\rho X_{n + 1} + (1-\\rho) \\tilde X_{n+1}$$\n\nwhere, $\\rho = \\{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\\}$\n\nTo forecast VaR, we solve the following equation:\n\n$$0.99 = P(\\rho X_{n + 1} + (1-\\rho) \\tilde X_{n+1} \\leq x | \\mathcal{F})$$ $$0.99 = P(\\rho(\\mu + \\phi X_{n} + \\sigma_{n+1}\\varepsilon_{n+1}) + (1-\\rho) (\\tilde\\mu + \\tilde\\phi \\tilde X_{n} + \\tilde \\sigma_{n+1} \\tilde \\varepsilon_{n+1}) \\leq x | \\mathcal{F})$$\n\nInitially, we forecast one step ahead $\\sigma_{n+1}$ and $\\tilde \\sigma_{n + 1}$ using the `ugarchforecast()` function. At this point, we have estimated all the unknowns in the $AR(1) + GARCH(1,1)$ model. In order to solve the above equation numerically, we draw a random sample of size $b = 10000$ from the fitted t-Copula and make transformations to get $\\varepsilon_i$ and $\\tilde \\varepsilon_i$, $i = 1, \\dots, b$ Lastly, we calculate VaR at 99% by calculating the 99th quantile of the following sample\n\n$$\\big{\\{}\\rho(\\mu + \\phi X_{n} + \\sigma_{n+1}\\varepsilon_{i}) + (1-\\rho) (\\tilde\\mu + \\tilde\\phi \\tilde X_{n} + \\tilde \\sigma_{n+1} \\tilde \\varepsilon_{i})\\big{\\}}_{i = 1}^b$$ In order to see how risk depends on share of portfolio $\\rho$, we conduct the empirical activity for $\\rho = 0.1, \\dots, 0.9$.\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-17_de1bee2b6169e275641e82b33b665a15'}\n\n```{.r .cell-code}\n# Copula Simulation \n\nb <- 10000\nrho = Ct@estimate[1]\ndf = Ct@estimate[2]\nsimulate <- rCopula(b, tCopula(dim = 2, rho, df = df))\nspxl_marginal <- qt(simulate[, 1], df = spxl_res_t$estimate[3])\nbac_marginal <- qt(simulate[, 2], df = bac_res_t$estimate[3])\n\n# dataframe with transformed marginals\nsim <- cbind(spxl_marginal, bac_marginal)\n\n# Forecasting sigmas\n\nspxl_pred <- ugarchforecast(spxl_fit, n.ahead = 1)\nbac_pred <- ugarchforecast(bac_fit, n.ahead = 1)\nspxl_sigma <- sigma(spxl_pred) # sigma_{t + 1}\nbac_sigma <- sigma(bac_pred) # sigma_{t + 1}\n\n# Vectorize parameters\ns_mu <- rep(as.numeric(spxl_fit@fit$coef[1]), b)\ns_ar <- rep(as.numeric(spxl_fit@fit$coef[2]), b)\ns_last <- rep(spxl[length(spxl)], b)\ns_sd <- rep(spxl_sigma, b)\n\nb_mu <- rep(as.numeric(bac_fit@fit$coef[1]), b)\nb_ar <- rep(as.numeric(bac_fit@fit$coef[2]), b)\nb_last <- rep(bac[length(bac)], b)\nb_sd <- rep(bac_sigma, b)\n\n\ns <- s_mu + (s_ar * s_last) + (s_sd * sim[, 1])\nba <- b_mu + (b_ar * b_last) + (b_sd * sim[, 2])\npred_sample <- cbind(s, ba)\nrhos <- seq(0.1, 0.9, by = 0.1)\nvar_sample <- data.frame()\n\nalpha <-  0.01 # 99th percentile\n\nportfolio_value <- 1000000\n\nfor (i in rhos){\n  \n  s_rho <- s * rep(i, b)\n  b_rho <- ba * rep(1 - i, b)\n  \n  sample <-  s_rho + b_rho\n  q <- as.numeric(quantile(sample, alpha))\n  VaR <- - portfolio_value * q\n  var_sample <- rbind(var_sample, VaR)\n}\n\nvar_sample$`SPXL Portfolio Weight` <- c(\"p = 0.1\", \"p = 0.2\", \"p = 0.3\", \"p = 0.4\", \n                           \"p = 0.5\", \"p = 0.6\", \"p = 0.7\", \"p = 0.8\", \n                           \"p = 0.9\")\n\n\n\ncolnames(var_sample) <- c(\"VaR ($)\", \"SPXL Portfolio Weight\")\n\n# Reordering columns\nvar_sample <- var_sample[, c(\"SPXL Portfolio Weight\", \"VaR ($)\")]\n\ndatasummary_df(var_sample,\n               title = \"Table 2. One-Step Ahead VaR forecast for a $1 million portfolio with varying weights\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Table 2. One-Step Ahead VaR forecast for a $1 million portfolio with varying weights</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> &nbsp;SPXL Portfolio Weight </th>\n   <th style=\"text-align:left;\"> &nbsp;VaR ($) \n  \n \n</caption>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.1 </td>\n   <td style=\"text-align:left;\"> 58694.27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.2 </td>\n   <td style=\"text-align:left;\"> 65955.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.3 </td>\n   <td style=\"text-align:left;\"> 73579.43 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.4 </td>\n   <td style=\"text-align:left;\"> 82912.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.5 </td>\n   <td style=\"text-align:left;\"> 91288.56 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.6 </td>\n   <td style=\"text-align:left;\"> 102194.88 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.7 </td>\n   <td style=\"text-align:left;\"> 111543.12 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.8 </td>\n   <td style=\"text-align:left;\"> 120811.33 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> p = 0.9 </td>\n   <td style=\"text-align:left;\"> 131710.86 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: justify\nThe table reports the Value-at-Risk at 99% level for a portfolio value of \\$1,000,000. It is evident from the table that as SPXL's proportion in the portfolio increases ($\\rho$), the Value-at-Risk increases. These results are in line with expectations as Direxion Daily S&P 500 Bull 3X Shares is a 300% leveraged instrument based on the S&P 500 index. When $\\rho = 0.2$, there is a 1% percent chance that the loss would be greater than NA the next day on a \\$1,000,000 investment. Similarly, When $\\rho = 0.9$, there is a 1% percent chance that the loss would be greater than NA the next day on a \\$1,000,000 investment.\n:::\n\n# Reference\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}